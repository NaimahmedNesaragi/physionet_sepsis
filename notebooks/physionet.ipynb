{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.experimental import enable_iterative_imputer  \n",
    "from sklearn.impute import IterativeImputer\n",
    "from cache_em_all import Cachable\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/raw/training\" # Path to the data\n",
    "\n",
    "# Names of all columns in the data that contain physiological data\n",
    "physiological_cols = ['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'EtCO2',\n",
    "       'BaseExcess', 'HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST', 'BUN',\n",
    "       'Alkalinephos', 'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct',\n",
    "       'Glucose', 'Lactate', 'Magnesium', 'Phosphate', 'Potassium',\n",
    "       'Bilirubin_total', 'TroponinI', 'Hct', 'Hgb', 'PTT', 'WBC',\n",
    "       'Fibrinogen', 'Platelets']\n",
    "\n",
    "# Names of all columns in the data that contain demographic data\n",
    "demographic_cols = ['Age', 'Gender', 'Unit1', 'Unit2', 'HospAdmTime', 'ICULOS']\n",
    "\n",
    "# The combination of physiological and demographic data is what we will use as features in our model\n",
    "feature_cols = physiological_cols + demographic_cols\n",
    "\n",
    "# The name of the column that contains the value we are trying to predic\n",
    "label_col = \"SepsisLabel\"\n",
    "\n",
    "# Pre-calculated means and standard deviation of all physiological and demographic columns. We will use this to normalize\n",
    "# data using their z-score. This isn't as important for simpler models such as random forests and decision trees,\n",
    "# but can result in significant improvements when using neural networks\n",
    "physiological_mean = np.array([\n",
    "        83.8996, 97.0520,  36.8055,  126.2240, 86.2907,\n",
    "        66.2070, 18.7280,  33.7373,  -3.1923,  22.5352,\n",
    "        0.4597,  7.3889,   39.5049,  96.8883,  103.4265,\n",
    "        22.4952, 87.5214,  7.7210,   106.1982, 1.5961,\n",
    "        0.6943,  131.5327, 2.0262,   2.0509,   3.5130,\n",
    "        4.0541,  1.3423,   5.2734,   32.1134,  10.5383,\n",
    "        38.9974, 10.5585,  286.5404, 198.6777])\n",
    "physiological_std = np.array([\n",
    "        17.6494, 3.0163,  0.6895,   24.2988, 16.6459,\n",
    "        14.0771, 4.7035,  11.0158,  3.7845,  3.1567,\n",
    "        6.2684,  0.0710,  9.1087,   3.3971,  430.3638,\n",
    "        19.0690, 81.7152, 2.3992,   4.9761,  2.0648,\n",
    "        1.9926,  45.4816, 1.6008,   0.3793,  1.3092,\n",
    "        0.5844,  2.5511,  20.4142,  6.4362,  2.2302,\n",
    "        29.8928, 7.0606,  137.3886, 96.8997])\n",
    "demographic_mean = np.array([60.8711, 0.5435, 0.0615, 0.0727, -59.6769, 28.4551])\n",
    "demographic_std = np.array([16.1887, 0.4981, 0.7968, 0.8029, 160.8846, 29.5367])\n",
    "\n",
    "@Cachable(\"flattened.csv\")\n",
    "def flatten(in_df, hours=4):\n",
    "    res = []\n",
    "\n",
    "    new_cols = []\n",
    "    for i in range(hours):\n",
    "        new_cols.append([c + \"_\" + str(i) for c in feature_cols])\n",
    "\n",
    "\n",
    "    df = in_df.sort_values(\"hours\")\n",
    "    for patient, _df in df.groupby(\"patient\"):\n",
    "        n = int(len(_df) / hours)\n",
    "\n",
    "        for i in range(n):\n",
    "            window = _df.iloc[i*hours:(i+1)*hours]\n",
    "            window_dict = {}\n",
    "\n",
    "            for j in range(hours):\n",
    "                for c in physiological_cols:\n",
    "                    window_dict[c + \"_\" + str(j)] = window[c].iloc[j]\n",
    "\n",
    "            for c in demographic_cols:\n",
    "                window_dict[c] = window[c].iloc[0]\n",
    "\n",
    "            window_dict[label_col] = window[label_col].mean()\n",
    "            window_dict[\"patient\"] = patient\n",
    "\n",
    "            res.append(window_dict)\n",
    "\n",
    "    res = pd.DataFrame(res)\n",
    "\n",
    "    res = res[res[label_col] <= 1 / hours]\n",
    "    res[label_col] = res[label_col].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_single_file(file_path):\n",
    "    df = pd.read_csv(file_path, sep='|')\n",
    "    df['hours'] = df.index\n",
    "    df['patient'] = file_path[22:-4]\n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_files():\n",
    "    return [os.path.join(DATA_DIR, x) for x in sorted(os.listdir(DATA_DIR)) if int(x[1:-4]) % 5 > 0]\n",
    "\n",
    "def clean_data(data):\n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # Normalizes physiological and demographic data using z-score.\n",
    "    data[physiological_cols] = (data[physiological_cols] - physiological_mean) / physiological_std\n",
    "    data[demographic_cols] = (data[demographic_cols] - demographic_mean) / demographic_std\n",
    "\n",
    "    # Maps invalid numbers (NaN, inf, -inf) to numbers (0, really large number, really small number)\n",
    "    data[feature_cols] = np.nan_to_num(data[feature_cols])\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "@Cachable(\"data.csv\")\n",
    "def load_data():\n",
    "    data = get_data_files()\n",
    "    data_frames = [clean_data(load_single_file(d)) for d in data]\n",
    "    merged = pd.concat(data_frames)\n",
    "    return merged\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(actual, predicted, prefix=\"\"):\n",
    "    precision = precision_score(actual, predicted)\n",
    "    recall = recall_score(actual, predicted)\n",
    "    accuracy = accuracy_score(actual, predicted)\n",
    "\n",
    "    print(\"%s Precision: %.3f%%, Recall: %.3f%%, Accuracy: %.3f%%\" % (prefix, precision * 100, recall * 100, accuracy * 100))\n",
    "\n",
    "def train_simple(data, feature_cols, label_col):\n",
    "    train_df, test_df = train_test_split(data, test_size=0.2)\n",
    "    train_X = train_df[feature_cols]\n",
    "    train_y = train_df[label_col]\n",
    "    test_X = test_df[feature_cols]\n",
    "    test_y = test_df[label_col]\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(train_X,train_y)\n",
    "    y_pred_train = clf.predict(train_X)\n",
    "    y_pred_test = clf.predict(test_X)\n",
    "    evaluate(train_y,y_pred_train,'train')\n",
    "    evaluate(test_y,y_pred_test,'test')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_stratified(data, feature_cols, label_col, stratify_col):\n",
    "#     X = data[feature_cols]\n",
    "#     y = data[label_col]\n",
    "#     group = data[stratify_col]\n",
    "\n",
    "#     train_pred = []\n",
    "#     train_actual = []\n",
    "\n",
    "#     test_pred = []\n",
    "#     test_actual = []\n",
    "\n",
    "#     kf = GroupKFold(n_splits=5)\n",
    "#     for train_idx, test_idx in kf.split(X, y, group):\n",
    "#         X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "#         X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
    "\n",
    "#         clf = MLPClassifier()\n",
    "#         clf.fit(X_train, y_train)\n",
    "\n",
    "#         train_pred.extend(clf.predict(X_train))\n",
    "#         train_actual.extend(y_train)\n",
    "\n",
    "#         test_pred.extend(clf.predict(X_test))\n",
    "#         test_actual.extend(y_test)\n",
    "\n",
    "\n",
    "\n",
    "#     evaluate(train_actual, train_pred, \"Train\")\n",
    "#     evaluate(test_actual, test_pred, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_stratified(data, feature_cols, label_col, stratify_col):\n",
    "    X = data[feature_cols]\n",
    "    y = data[label_col]\n",
    "    group = data[stratify_col]\n",
    "\n",
    "    train_pred = []\n",
    "    train_actual = []\n",
    "\n",
    "    test_pred = []\n",
    "    test_actual = []\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=2)\n",
    "    for train_idx, test_idx in kf.split(X, y, group):\n",
    "        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
    "        return X_train, X_test, y_train, y_test\n",
    "#         clf = RandomForestClassfier()\n",
    "#         clf.fit(X_train, y_train)\n",
    "#         train_pred.extend(clf.predict(X_train))\n",
    "#         train_actual.extend(y_train)\n",
    "\n",
    "#         test_pred.extend(clf.predict(X_test))\n",
    "#         test_actual.extend(y_test)\n",
    "\n",
    "\n",
    "\n",
    "#     evaluate(train_actual, train_pred, \"Train\")\n",
    "#     evaluate(test_actual, test_pred, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n",
      "TRAIN: [1 3] TEST: [0 2]\n",
      "TRAIN: [0 2] TEST: [1 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([0, 0, 1, 1])\n",
    "skf = StratifiedKFold(n_splits=2)\n",
    "groups = np.array([0, 0, 2, 2])\n",
    "skf.get_n_splits(X, y,groups)\n",
    "\n",
    "print(skf)\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "   print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "   X_train, X_test = X[train_index], X[test_index]\n",
    "   y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'EtCO2',\n",
       "       'BaseExcess', 'HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST', 'BUN',\n",
       "       'Alkalinephos', 'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct',\n",
       "       'Glucose', 'Lactate', 'Magnesium', 'Phosphate', 'Potassium',\n",
       "       'Bilirubin_total', 'TroponinI', 'Hct', 'Hgb', 'PTT', 'WBC',\n",
       "       'Fibrinogen', 'Platelets', 'Age', 'Gender', 'Unit1', 'Unit2',\n",
       "       'HospAdmTime', 'ICULOS', 'SepsisLabel', 'hours', 'patient'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_data()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Precision: 99.982%, Recall: 100.000%, Accuracy: 100.000%\n",
      "test Precision: 34.469%, Recall: 32.565%, Accuracy: 97.200%\n"
     ]
    }
   ],
   "source": [
    "train_simple(df,feature_cols,label_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest n_estimators=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zacharybarnes/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Precision: 99.903%, Recall: 83.526%, Accuracy: 99.637%\n",
      "test Precision: 87.500%, Recall: 4.345%, Accuracy: 97.911%\n"
     ]
    }
   ],
   "source": [
    "train_simple(df,feature_cols,label_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest n_estimators=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Precision: 99.973%, Recall: 99.936%, Accuracy: 99.998%\n",
      "test Precision: 90.977%, Recall: 4.357%, Accuracy: 97.887%\n"
     ]
    }
   ],
   "source": [
    "train_simple(df,feature_cols,label_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Precision: 67.600%, Recall: 5.011%, Accuracy: 97.864%\n",
      "test Precision: 33.862%, Recall: 2.350%, Accuracy: 97.795%\n"
     ]
    }
   ],
   "source": [
    "train_simple(df,feature_cols,label_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_simple(df,feature_cols,label_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision: 78.186%, Recall: 5.702%, Accuracy: 97.904%\n",
      "Test Precision: 11.822%, Recall: 1.848%, Accuracy: 97.553%\n"
     ]
    }
   ],
   "source": [
    "train_stratified(df, feature_cols, label_col, 'patient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flattened CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = flatten(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_feat_cols = [x for x in flat.columns if x not in [label_col,'patient']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_stratified_balanced(data, feature_cols, label_col):\n",
    "    \n",
    "    labels = data.groupby(['patient']).agg({'SepsisLabel':'sum'})['SepsisLabel']\n",
    "    positive_index = labels.loc[(labels == 1)].index\n",
    "    size = int(len(positive_index)/2)\n",
    "    half_positive_index = np.random.choice(positive_index, size, replace=False)\n",
    "    X_train_full = data[~data['patient'].isin(half_positive_index)]\n",
    "    train_labels = X_train_full.groupby('patient').agg({'SepsisLabel':'sum'})['SepsisLabel']\n",
    "    negative_index = train_labels.loc[(train_labels == 0)].index\n",
    "    size = int(len(negative_index)*0.2)\n",
    "    small_negative_index = np.random.choice(negative_index, size, replace=False)\n",
    "    train_df = X_train_full[~X_train_full['patient'].isin(small_negative_index)]\n",
    "    test_df = data.loc[(data['patient'].isin(half_positive_index)) | (data['patient'].isin(small_negative_index))]\n",
    "    \n",
    "    \n",
    "    train_X = train_df[feature_cols]\n",
    "    train_y = train_df[label_col]\n",
    "    test_X = test_df[feature_cols]\n",
    "    test_y = test_df[label_col]\n",
    "    clf = RandomForestClassifier(n_estimators=100)\n",
    "    clf.fit(train_X,train_y)\n",
    "    y_pred_train = clf.predict(train_X)\n",
    "    y_pred_test = clf.predict(test_X)\n",
    "    evaluate(train_y,y_pred_train,'train')\n",
    "    evaluate(test_y,y_pred_test,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Precision: 99.985%, Recall: 99.942%, Accuracy: 99.998%\n",
      "test Precision: 0.000%, Recall: 0.000%, Accuracy: 99.993%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zacharybarnes/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "train_stratified_balanced(df,feature_cols,label_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    108884\n",
       "Name: SepsisLabel, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Precision: 100.000%, Recall: 100.000%, Accuracy: 100.000%\n",
      "test Precision: 0.000%, Recall: 0.000%, Accuracy: 99.449%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zacharybarnes/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "train_stratified_balanced(flat,flattened_feat_cols,label_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
